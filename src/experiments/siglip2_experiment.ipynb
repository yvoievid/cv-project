{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(\"..\"))  \n",
    "from models.ui_dataset import UIDataset\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "import torch\n",
    "import wandb\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score, recall_score, precision_score\n",
    "from wandb.integration.xgboost import WandbCallback\n",
    "from transformers import AutoModel, AutoProcessor\n",
    "from transformers.image_utils import load_image\n",
    "from PIL import Image\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7735e7fca18b4dbeab68b516e8d71b9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/368 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c28cc6ba418f408a8aea500dcea4f3b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/711 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d968abcc2e9e42bea351367e14ca4199",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/798k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a7bbe35d6384323bba8e44b32c50a9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/409 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2c077865c97416193644d2ede9f6e37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.40M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ckpt = \"google/siglip2-base-patch16-256\"\n",
    "model = AutoModel.from_pretrained(ckpt, device_map=\"auto\").eval()\n",
    "processor = AutoProcessor.from_pretrained(\"google/siglip-base-patch16-256\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/130 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 58/130 [01:28<01:48,  1.50s/it]/Users/yuriivoievidka/.pyenv/versions/3.12.7/envs/torch/lib/python3.12/site-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "100%|██████████| 130/130 [02:47<00:00,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings shape: torch.Size([4149, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset_path = \"/Users/yuriivoievidka/UCU/CV/cv-project/data\"\n",
    "\n",
    "ui_dataset_all = UIDataset(root_dir=dataset_path, processor=processor)\n",
    "ui_dataset_all_dataloader = DataLoader(ui_dataset_all, batch_size=32, shuffle=False)\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    all_embeddings = []\n",
    "    for batch in tqdm(ui_dataset_all_dataloader):\n",
    "        images, labels = batch\n",
    "        images = images.to(device)\n",
    "\n",
    "        inputs = {\"pixel_values\": images}  \n",
    "        embeddings = model.get_image_features(**inputs) \n",
    "\n",
    "        embeddings /= embeddings.norm(dim=-1, keepdim=True)\n",
    "        all_embeddings.append(embeddings.cpu())\n",
    "\n",
    "    all_embeddings = torch.cat(all_embeddings, dim=0)\n",
    "\n",
    "print(\"Embeddings shape:\", all_embeddings.shape)\n",
    "\n",
    "# Convert embeddings to numpy\n",
    "all_embeddings_np = all_embeddings.numpy()\n",
    "\n",
    "# Encode labels as integers\n",
    "label_to_index = {label: idx for idx, label in enumerate(set(label for _, label in ui_dataset_all.image_paths))}\n",
    "all_labels_np = np.array([label_to_index[label] for _, label in ui_dataset_all.image_paths])\n",
    "\n",
    "# Save embeddings and labels\n",
    "np.save(\"siglip_embeddings.npy\", all_embeddings_np)\n",
    "np.save(\"siglip_labels.npy\", all_labels_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = np.load(\"siglip_embeddings.npy\")  \n",
    "labels = np.load(\"siglip_labels.npy\")  \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(embeddings, labels, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "    \"method\": \"random\", \n",
    "    \"metric\": {\n",
    "      \"name\": \"f1_score\",\n",
    "      \"goal\": \"maximize\"   \n",
    "    },\n",
    "    \"parameters\": {\n",
    "        \"booster\": {\n",
    "            \"values\": [\"gbtree\",\"gblinear\"]\n",
    "        },\n",
    "        \"max_depth\": {\n",
    "            \"values\": [3, 6, 9, 12]\n",
    "        },\n",
    "        \"learning_rate\": {\n",
    "            \"values\": [0.1, 0.05, 0.2]\n",
    "        },\n",
    "        \"subsample\": {\n",
    "            \"values\": [1, 0.5, 0.3]\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: tx1ewc0i\n",
      "Sweep URL: https://wandb.ai/urik-voevidka-ukrainian-catholic-university/ui-classification-experiments/sweeps/tx1ewc0i\n"
     ]
    }
   ],
   "source": [
    "sweep_id = wandb.sweep(sweep_config, project=\"ui-classification-experiments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "  config={\n",
    "        \"learning_rate\": 0.02,\n",
    "        \"architecture\": \"XGBoost\",\n",
    "        \"dataset\": \"DesktopUI\",\n",
    "        \"epochs\": 100,\n",
    "        \"model\": \"SigLIP\",\n",
    "        \"test_size\": 0.3,\n",
    "        \"random_state\": 42\n",
    "    }\n",
    "\n",
    "  wandb.init(config=config)\n",
    "  config = wandb.config\n",
    "\n",
    "  model = xgb.XGBClassifier(objective=\"multi:softmax\", booster=config.booster, max_depth=config.max_depth,\n",
    "                        learning_rate=config.learning_rate, subsample=config.subsample)\n",
    "  model.fit(X_train, y_train)\n",
    "\n",
    "  y_pred = model.predict(X_test)\n",
    "  predictions = [round(value) for value in y_pred]\n",
    "\n",
    "  accuracy = accuracy_score(y_test, predictions)\n",
    "  \n",
    "  f1 = f1_score(y_test, predictions, average=\"weighted\")\n",
    "  recall = recall_score(y_test, predictions, average=\"weighted\")\n",
    "  precision = precision_score(y_test, predictions, average=\"weighted\")\n",
    "\n",
    "  wandb.log({\n",
    "      \"accuracy\": accuracy,\n",
    "      \"f1_score\": f1,\n",
    "      \"recall\": recall, \n",
    "      \"precision\": precision,\n",
    "      \"classification_report\": classification_report(y_test, predictions, output_dict=True)\n",
    "  })\n",
    "  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
